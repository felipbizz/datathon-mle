# Sistema de PrevisÃ£o de Sucesso de Candidatos

## VisÃ£o Geral do Projeto

Este projeto demonstra a implementaÃ§Ã£o de um pipeline completo de Engenharia de Machine Learning (MLE) para prever o sucesso de candidatos em processos seletivos. O sistema integra prÃ¡ticas modernas de MLE, incluindo versionamento de modelos, implantaÃ§Ã£o de API e capacidades de inferÃªncia.

## ğŸ¯ Objetivos do Projeto

- Desenvolver um pipeline robusto de ML para previsÃ£o de sucesso de candidatos
- Implementar melhores prÃ¡ticas de MLOps para implantaÃ§Ã£o e monitoramento de modelos
- Criar um sistema pronto para produÃ§Ã£o com interfaces de API e frontend
- Demonstrar o gerenciamento do ciclo de vida completo de ML

## ğŸ—ï¸ Arquitetura do Sistema

O projeto segue uma arquitetura modular com trÃªs componentes principais:

### 1. Pacote Core de ML (`mle_datathon`)
- ImplementaÃ§Ã£o modular do pipeline de ML
- Processamento de dados e engenharia de features
- Treinamento e avaliaÃ§Ã£o de modelos
- Registro e versionamento de modelos usando MLflow

### 2. ServiÃ§o de API (FastAPI)
- API RESTful para inferÃªncia de modelos
- Gerenciamento e versionamento de modelos
- Endpoints de prediÃ§Ã£o
- ContainerizaÃ§Ã£o com Docker

### 3. AplicaÃ§Ã£o Frontend (Streamlit)
- VisualizaÃ§Ã£o interativa de dados
- Interface de prediÃ§Ã£o
- Monitoramento de performance do modelo
- AnÃ¡lise amigÃ¡vel de candidatos

## ğŸ› ï¸ Stack TecnolÃ³gica

### Machine Learning & Processamento de Dados
- **ML Core**: Scikit-learn, XGBoost, LightGBM
- **Engenharia de Features**: Pandas, Polars, PyArrow
- **Explicabilidade de Modelos**: SHAP, LIME
- **Processamento de NLP**: NLTK, Sentence Transformers
- **ValidaÃ§Ã£o de Dados**: Pandera

### MLOps & ImplantaÃ§Ã£o
- **Registro de Modelos**: MLflow
- **Framework de API**: FastAPI
- **ContainerizaÃ§Ã£o**: Docker
- **Frontend**: Streamlit
- **Testes**: Pytest, Coverage

### Ferramentas de Desenvolvimento
- **Gerenciamento de Pacotes**: UV
- **Qualidade de CÃ³digo**: Pre-commit hooks
- **Controle de VersÃ£o**: Git
- **DocumentaÃ§Ã£o**: Markdown

## ğŸ“¦ Estrutura do Projeto

```
â”œâ”€â”€ api/                    # ServiÃ§o FastAPI
â”‚   â”œâ”€â”€ controllers/       # Endpoints da API
â”‚   â”œâ”€â”€ main.py           # Ponto de entrada da API
â”‚   â””â”€â”€ Dockerfile        # ConfiguraÃ§Ã£o do container
â”œâ”€â”€ front/                 # Frontend Streamlit
â”‚   â””â”€â”€ app.py            # AplicaÃ§Ã£o web
â”œâ”€â”€ packages_src/          # Pacote core de ML
â”‚   â””â”€â”€ mle_datathon/     # ImplementaÃ§Ã£o do pipeline de ML
â”œâ”€â”€ tests/                # SuÃ­te de testes
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”œâ”€â”€ infra/               # CÃ³digo de infraestrutura
â””â”€â”€ main.py              # Ponto de entrada principal
```

## ğŸš€ ComeÃ§ando

### PrÃ©-requisitos
- Python 3.12+
- Docker
- Gerenciador de pacotes UV
- Make (geralmente jÃ¡ instalado em sistemas Unix)

### InstalaÃ§Ã£o e ExecuÃ§Ã£o

1. **Clone o repositÃ³rio**
   ```bash
   git clone [url-do-repositorio]
   cd datathon-mle
   ```

2. **Instale as dependÃªncias**
   ```bash
   uv pip install -r pyproject.toml
   ```

3. **Inicialize a Infraestrutura**
   ```bash
   make create-infra
   ```
   Este comando irÃ¡:
   - Criar a estrutura de pastas necessÃ¡ria
   - Configurar os containers Docker
   - Inicializar o MLflow
   - Configurar o ambiente de desenvolvimento

4. **Adicione os Dados**
   - ApÃ³s a inicializaÃ§Ã£o, adicione os dados brutos na pasta `Datathon Decision/1_raw`

### Comandos Principais

#### Infraestrutura
```bash
make create-infra     # Cria toda a infraestrutura necessÃ¡ria
make start-infra      # Inicia os containers existentes
make stop-infra       # Para os containers sem removÃª-los
make destroy-infra    # Remove todos os containers
```

#### Pipeline de ML
```bash
make pipeline         # Executa o pipeline completo
make preprocess       # Executa apenas o prÃ©-processamento
make train           # Executa apenas o treinamento do modelo
make tune            # Executa o ajuste de hiperparÃ¢metros
```

#### Testes
```bash
make test                    # Executa todos os testes
make test-feature-engineering # Testa a engenharia de features
make test-preprocess         # Testa o prÃ©-processamento
make test-target            # Testa a definiÃ§Ã£o do target
make test-consolidate       # Testa a consolidaÃ§Ã£o de dados
make test-training          # Testa o treinamento do modelo
```

#### Frontend e API
```bash
make front-end      # Inicia a aplicaÃ§Ã£o Streamlit
make build-api-image # ConstrÃ³i a imagem Docker da API
```

#### Gerenciamento de Modelos
```bash
make list_registered_models  # Lista os modelos registrados
make purge_experiments       # Limpa o banco de dados de experimentos
make list_experiments        # Lista os experimentos do MLflow
```

#### Ajuda
```bash
make help           # Mostra todos os comandos disponÃ­veis
```

### ObservaÃ§Ãµes Importantes

1. **Primeira ExecuÃ§Ã£o**
   - Execute `make create-infra` para configurar todo o ambiente
   - Adicione os dados brutos na pasta correta
   - Verifique se todos os serviÃ§os estÃ£o rodando com `docker ps`

2. **Ambiente de Desenvolvimento**
   - O MLflow estarÃ¡ disponÃ­vel em `http://localhost:5000`
   - A API estarÃ¡ disponÃ­vel em `http://localhost:8000`
   - O frontend estarÃ¡ disponÃ­vel em `http://localhost:8501`

3. **SoluÃ§Ã£o de Problemas**
   - Se encontrar problemas de permissÃ£o, execute `make adjust-permissions`
   - Para reiniciar do zero, use `make destroy-infra` seguido de `make create-infra`

4.  **Frontend:**
   ```bash
   streamlit run front/app.py
   ```

## ğŸ§ª Executando o Pipeline de ML

O pipeline principal pode ser executado usando os seguintes comandos:

```bash
# Pipeline completo
python main.py --steps full_pipeline

# Passos individuais
python main.py --steps preprocess consolidate define_target feature_engineering train_model
```

## ğŸ“Š Performance do Modelo

O projeto implementa um framework abrangente de avaliaÃ§Ã£o de modelos:
- MÃ©tricas de validaÃ§Ã£o cruzada
- AnÃ¡lise de importÃ¢ncia de features
- Explicabilidade do modelo usando valores SHAP
- Monitoramento de performance em produÃ§Ã£o

## ğŸ” Funcionalidades Principais

1. **Pipeline de Processamento de Dados**
   - Limpeza automatizada de dados
   - Engenharia de features
   - ValidaÃ§Ã£o de dados
   - Versionamento de pipeline

2. **Gerenciamento de Modelos**
   - Versionamento de modelos com MLflow
   - Capacidades de teste A/B
   - Monitoramento de performance do modelo
   - Gatilhos de retreinamento automatizado

3. **ImplantaÃ§Ã£o em ProduÃ§Ã£o**
   - ServiÃ§os containerizados
   - Arquitetura API-first
   - InferÃªncia
   - Infraestrutura escalÃ¡vel

## ğŸ§ª Testes

Execute a suÃ­te de testes:
```bash
pytest tests/
```

## ğŸ“š DocumentaÃ§Ã£o

- DocumentaÃ§Ã£o da API: `http://localhost:8000/docs`
- Tracking do MLflow: `http://localhost:5000`
- Interface Streamlit: `http://localhost:8501`

## ğŸ¤ Contribuindo

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch para sua feature
3. FaÃ§a commit das suas alteraÃ§Ãµes
4. FaÃ§a push para a branch
5. Abra um Pull Request

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo LICENSE para detalhes.